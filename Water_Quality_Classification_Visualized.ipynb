{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f96926",
   "metadata": {},
   "source": [
    "# Predicting Water Quality Using Machine Learning\n",
    "Author: **Fabrice Faustin**  \n",
    "This notebook demonstrates the application of supervised machine learning techniques to predict groundwater quality using a dataset from Telangana, India (2018).\n",
    "We'll walk through preprocessing, modeling (Decision Tree and KNN), cross-validation, and comparison of performance using accuracy and precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e9e67",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n",
    "We select only numeric features relevant for analysis and handle nulls as 0.0, following the same methodology used in the original study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c856cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "file_path = 'ground_water_quality_2018_post.csv'\n",
    "feature_indices = list(range(4, 7)) + list(range(8, 23))\n",
    "target_index = 23\n",
    "\n",
    "features = []\n",
    "target = []\n",
    "\n",
    "with open(file_path, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    headers = next(csv_reader)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            selected_features = [float(row[i]) if row[i] else 0.0 for i in feature_indices]\n",
    "            if len(selected_features) != len(feature_indices):\n",
    "                continue\n",
    "            features.append(selected_features)\n",
    "            target.append(row[target_index])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "X = pd.DataFrame(features, columns=[headers[i] for i in feature_indices])\n",
    "y = pd.Series(target, name=\"Classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc53c2",
   "metadata": {},
   "source": [
    "## 2. Remove Rare Classes\n",
    "To ensure valid stratified splits and meaningful cross-validation, we drop classes with fewer than 2 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b86a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = y.value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "mask = y.isin(valid_classes)\n",
    "X = X[mask]\n",
    "y = y[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c5ae3f",
   "metadata": {},
   "source": [
    "## 3. Encode Target and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae2ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97381a3a",
   "metadata": {},
   "source": [
    "## 4. Train Models and Evaluate\n",
    "We use 5-fold cross-validation and calculate both mean accuracy and precision on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18969def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "\n",
    "# Decision Tree\n",
    "for depth in [3, 5, 7]:\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    results.append({\n",
    "        'Model': 'Decision Tree',\n",
    "        'Hyperparameter': depth,\n",
    "        'CV Mean Accuracy': np.mean(cv_scores),\n",
    "        'Precision': precision\n",
    "    })\n",
    "\n",
    "# KNN\n",
    "for k in [5, 10, 15]:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    results.append({\n",
    "        'Model': 'KNN',\n",
    "        'Hyperparameter': k,\n",
    "        'CV Mean Accuracy': np.mean(cv_scores),\n",
    "        'Precision': precision\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a305bb0",
   "metadata": {},
   "source": [
    "## 5. Visualize Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328de0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=results_df, x=\"Hyperparameter\", y=\"CV Mean Accuracy\", hue=\"Model\")\n",
    "plt.title(\"Mean Cross-Validation Accuracy by Model and Hyperparameter\")\n",
    "plt.ylabel(\"Mean Accuracy\")\n",
    "plt.xlabel(\"Depth (Decision Tree) / K (KNN)\")\n",
    "plt.grid(axis='y')\n",
    "plt.legend(title='Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5dfd2",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "- The **Decision Tree (depth=5)** achieved the best combination of accuracy (~91.6%) and precision.\n",
    "- **KNN** performed best in accuracy at **k=10**, though slightly lower in precision.\n",
    "- Class imbalance was significant and could be further addressed using resampling techniques.\n",
    "- This project illustrates the end-to-end workflow of a classification pipeline in machine learning, grounded in real-world water quality data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
